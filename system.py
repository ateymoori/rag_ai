from transformers import AutoModelForCausalLM, AutoTokenizer
import sqlite3
import hashlib
from datetime import datetime
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)

# Function to load the LLaMA model
def load_model():
    model_name = "TheBloke/nsql-llama-2-7B-GGUF"
    model = AutoModelForCausalLM.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    logging.info("Model loaded successfully.")
    return model, tokenizer

# Function to connect to SQLite Database
def connect_to_db(db_file):
    conn = sqlite3.connect(db_file)
    logging.info("Connected to SQLite database.")
    return conn

# Function to fetch data from database
def fetch_data_from_db(conn, query):
    cur = conn.cursor()
    cur.execute(query)
    rows = cur.fetchall()
    logging.info(f"Fetched {len(rows)} rows from the database.")
    return rows

# Function to retrieve and process data
def retrieve_and_process_data(conn):
    query = "SELECT content FROM web_pages"
    data = fetch_data_from_db(conn, query)
    processed_data = [item[0] for item in data]  # Extracting content from tuples
    logging.info("Data processed for model input.")
    return processed_data

# Function to generate a response using the model
def generate_response(question, context, model, tokenizer):
    input_text = f"Question: {question}\nContext: {context}\nAnswer:"
    input_ids = tokenizer.encode(input_text, return_tensors='pt')
    output = model.generate(input_ids, max_length=500)
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    logging.info("Response generated by the model.")
    return response

# Main function to bring everything together
def main():
    db_file = 'scraped_data.db'
    model, tokenizer = load_model()
    conn = connect_to_db(db_file)
    context_data = retrieve_and_process_data(conn)

    # Example usage
    question = "What is the main topic of the website?"
    for context in context_data:
        response = generate_response(question, context, model, tokenizer)
        print(response)
        # Add more logic as needed

    conn.close()

if __name__ == "__main__":
    main()
