Boost Chatbot — SBAB Docs  documentation SBAB Docs Ansible Controller Ansible Roles Ansible Vault Argo Workflows Authentication & Authorization Bitbucket Boost Chatbot Overview Docker images Update 1. Install/Configure AWS CLI 2. Pull/Push Docker images 3. Update Operator deployment 4. Update stack config Training Application stack Kubernetes cluster Setting data center Namespace External configuration/code Database Login to database Images SBAB Deployment from scratch Helm charts SFTP SFTP jobs Configure directories Manual backup Restore from backup Check on scheduled backups Database jobs Manual backup Restore from backup Check on scheduled backups Restore from Boost cloud backup Operator Stack Booli Ceph Dex Fortigate troubleshooting Generate certificate Go GitHub Copilot GitLab @Sbab User Guide GitLab Maintenance Grafana Istio Java Jenkins Jenkinsfile Jmeter Kafka Maintenance Kafka @Sbab User Guide Kafka Connect Kubectl Access Kubernetes Lab environment Local Open Web Metrics infrastructure MongoDB Netbox NVIDIA Neo4J Sonatype Nexus repository Oracle OWASP Database OWASP @Sbab User Guide Pact Principles of Security Prometheus ReactJS Redis Renovate S3 Security Guidelines for Developers Sentry Maintenance Sentry User Guide Configuring Variables for Services Deployed to Kubernetes Software Architecture SonarQube Maintenance SonarQube User Guide Structurizr System Landscape Vagrant Zipkin Windows Pipelines SBAB Docs » Boost Chatbot View page source Boost Chatbot ï Upstream website: boost.ai Application stack: gitlab.sbab.se/customer-communication/boost-chat Official installation manual from Boost Overview ï All components runs on Kubernetes . Overview of components from the ground up: SFTP server - file storage for Boost applications PostgreSQL database Boost operator - manages Boost stack instances Boost stack - The Kubernetes CRD defining a Boost application stack that is managed by the operator Docker images ï New Docker images from Boost needs to be manually downloaded and then uploaded to our own registry in Nexus. Update ï 1. Install/Configure AWS CLI ï Install AWS CLI Configure AWS CLI, see Vault Credentials vault/tnt/boost-chatbot : aws configure # Default region name [None]: eu-west-1 # Default output format [None]: Login to AWS registry: aws ecr get - login - password -- region eu - west - 1 | docker login -- username AWS -- password - stdin 194144427667. dkr . ecr . eu - west - 1. amazonaws . com 2. Pull/Push Docker images ï Get releases for the new version (e.g. 11.1.6): aws s3 -- region eu - west - 1 cp s3 : // onprem - configuration / SBAB / 11.1.6 / release . json . Login to our Nexus registry: docker login nexus . common . sbab . se : 18443 Pull each image and push to Nexus: function pull_push() {
   local BOOST_IMAGE="${1}"

   docker pull $BOOST_IMAGE
   IMAGE_TAG=${BOOST_IMAGE#*amazonaws.com/}
   NEXUS_IMAGE="nexus.common.sbab.se:18443/boost.ai/$IMAGE_TAG"
   docker tag $BOOST_IMAGE $NEXUS_IMAGE
   docker push $NEXUS_IMAGE
}

operatorImage=$(jq -r '.spec.operator_image' release.json)
pull_push $operatorImage

jq -r '.spec.images | values[]' release.json |
while IFS= read -r boostImage; do
   pull_push $boostImage
done 3. Update Operator deployment ï Update the operator deployment image with the new operator_image version Push and deploy: boost-chat/-/pipelines 4. Update stack config ï WARNING: If spec.config.database_version_before does not exist in release.json , remove it from stack/k8s/templates/stack.yaml . Update all Docker images (suffixed with Image ) in stack/k8s/values.yaml Based on the new release.json versions Update the databaseVersion in stack/k8s/values.yaml Push and deploy: boost-chat/-/pipelines Wait for the db-migrate job to start and follow the logs: kubectl - n boost - chat - sys logs - f job / db - migrate Verify that the logs from the operator boost-op are successful: kubectl - n boost - chat - sys logs - f deploy / boost - op Training ï The training of the model can take some hours to complete, depending on how big the data model is. Some useful commands: Check status of training pod: kubectl -n boost-chat-sys get pod -l app=training Check logs of the training container: kubectl -n boost-chat-sys logs -f <training pod> -c training Check logs of the upload container: kubectl -n boost-chat-sys logs -f <training pod> -c upload Application stack ï All the applications are packaged as Helm charts and deployed on Kubernetes. database_jobs/k8s : Helm chart for database backup/restore jobs images_sbab : Docker images with tools used for backup/restore used in database_jobs and sftp_jobs operator/k8s : Helm chart for the Boost operator sftp/k8s : Helm chart for the SFTP server sftp_jobs/k8s : Helm chart for SFTP backup/restore jobs stack/k8s : Helm chart for the Boost stack .gitlab-ci.yml : The pipeline handling deployment of all the above Kubernetes cluster ï The components are deployed in the oscommon environment, in one of the two Kubernetes clusters managed by team TNT; Kista (ki) or Upplands-VÃ¤sby (uv). To access these clusters with tools for working with Kubernetes, please see the README in tnt/k8s-rbac-for-ad-users-groups . Any kubectl or helm commands in this document assumes you are selecting namespace correctly, ie: kubectl - n boost - chat - sys get pods kubectl - n boost - chat - prod get pods Setting data center ï Currently we deploy the test environment to the Upplands-VÃ¤sby (uv) cluster in the oscommon environment. This is set in .deploy.variables.DC in this repositoryâs .gitlab-ci.yml file. The production environment is deployed to the Kista (ki) cluster in the oscommon environment. See the if clause in the .deploy job defined in .gitlab-ci.yml Namespace ï The components are deployed in the Kubernetes namespace boost-chat-<env> , ie. boost-chat-sys for the test environment. External configuration/code ï While I have tried to gather everything in this repo, some things need to live elsewhere. In the AFTO/ansible repo we have: inventories/os<env>/group_vars/all/boost_vault.yml which contains some secret and settings for the entire stack inventories/os<env>/group_vars/all/boost_postgres_cluster.yml which contains the configuration of the PostgreSQL database Where <env> is one of sys and prod . For information on working with Ansible see SBAB docs . Database ï For configuration of the PostgreSQL database server, see the above section âExternal configuration/codeâ. When you have made configuration changes, run the pipeline in this repo to apply the changes. You can inspect the current configuration with: kubectl get postgresql cc - boost - o yaml To check on the pods: kubectl get pods - l team = cc Login to database ï Login: kubectl - n boost - chat - sys exec - it deploy / psql -- psql - f - boostdb Query example: select * from version_info ; Images SBAB ï There are two Docker images in this repo used by the Helm charts database_jobs and sftp_jobs to handle backup/restore. The Docker images are only built/pushed when there have been changes to: images_sbab/postgres-tools-12.Dockerfile images_sbab/sftp-tools.Dockerfile Deployment from scratch ï I say âfrom scratchâ but we have only ever done it with database dumps from the Boost cloud environment.. All examples below is for the sys environment, replace sys with prod if deploying the prod environment. To start off you will need to set some values in database_jobs/k8s/values.yaml : doRestoreFromBoostBackup : true restoreURL : "url-to-boost-backup-zip-archive" Next run the pipeline in Gitlab for the environment you are deploying. The database import takes ~30min, check on status with: kubectl - n boost - chat - sys get job restoredb - boost - dbjobs Once the import is completed you need to delete the Boost stack as the initialization will have failed because the database was not ready: kubectl - n boost - chat - sys delete stack boostai - stack Revert your changes to database_jobs/k8s/values.yaml and run the pipeline again. This time you wait (~4min) for the job db-init to complete, at that point the Boost applications will begin starting up. Reset the password for the âadminâ user in Boost to âdefaultpasswordâ, in the directory manual_stuff execute the script: $ bash create-admin.sh sys Create some keys stuff (ask Boost or read the installation manual for details): $ bash cms-keys-install.sh sys Helm charts ï For all Helm charts, please review k8s/values.yaml to see the configuration. You will notice a lot of the configurationen references variables starting with vault_ - these can be found in the boost_vault.yml file detailed above under âExternal configuration/codeâ. SFTP ï This Helm chart deploys the SFTP server used by the Boost applications. It is unlikely any changes will be needed. At some point you might need to redeploy it with a larger disk but that should be long into the future. SFTP jobs ï This Helm chart deploys the Kubernetes CronJob to take daily backups of the SFTP server and upload to Nexus. There is also a job that handles initial setup of required directories on the SFTP server. Configure directories ï The Job creates some required directories on the SFTP server and uploads the enckey and sigkey files. The Job is always present in Kubernetes, but will only run once - when you first deploy the SFTP jobs. You can read the logs of the job with: kubectl logs job / configure - sftp - keys - sftpjobs Manual backup ï To trigger a backup right away, edit sftp_jobs/k8s/values.yaml and set: doManualBackup : true Commit the file to run the pipeline and perform the backup, you can check status with: kubectl get job manual - backup - sftp - sftpjobs Restore from backup ï To restore from backup, edit sftp_jobs/k8s/values.yaml and set: doRestoreFromBackup : true restoreURL : "url-to-backup-file-in-nexus" Commit the file to run the pipeline and perform the restore, you can check status with: kubectl get job restoresftp - sftpjobs When you are done, revert the changes you made to sftp_jobs/k8s/values.yaml . Check on scheduled backups ï To see how the scheduled backups have been doing you can run: kubectl get job The backup jobs for the SFTP server are prefixed with backupsftp . Database jobs ï This Helm chart deploys the Kubernetes CronJob to take daily backups of the PostgreSQL database server and upload to Nexus. Manual backup ï To trigger a backup right away, edit database_jobs/k8s/values.yaml and set: doManualBackup : true Commit the file to run the pipeline and perform the backup, you can check status with: kubectl get job manual - backup - db - dbjobs Restore from backup ï To restore from backup, edit database_jobs/k8s/values.yaml and set: doRestoreFromBackup : true restoreURL : "url-to-backup-file-in-nexus" Commit the file to run the pipeline and perform the restore, you can check status with: kubectl get job restoredb - dbjobs When you are done, revert the changes you made to database_jobs/k8s/values.yaml . Check on scheduled backups ï To see how the scheduled backups have been doing you can run: kubectl get job The backup jobs for the PostgreSQL database server are prefixed with backupdb . Restore from Boost cloud backup ï Boost makes the backup available to us on the AWS S3 fileshare: $ aws s3 --region eu-west-1 ls s3://onprem-configuration/SBAB/
                           PRE 11.1.3/
2021-05-26 11:17:11          0
2021-09-23 10:10:08       1937 README
2021-06-10 08:44:13  546687758 SBABDumpNoConvs2021-06-10.zip
2021-09-22 12:56:05  689695054 SBABDumpNoConvs2021-09-22.zip Download the zip archive you want and then upload it to Nexus, preferably in the below path: https : // nexus . common . sbab . se : 8443 / repository / sbab - software / boost - chat - sys / Obviously replace âsysâ with the environment you want to restore the backup in. Now you can run the restore job by setting the below values in database_jobs/k8s/values.yaml : doRestoreFromBoostBackup : true restoreURL : "url-to-the-zip-archive-in-nexus" Commit the changes to run the pipeline. The import takes about 40 minutes, you can check on the status with: kubectl get job restoredb - boost - dbjobs And of course read the logs with: kubectl logs job / restoredb - boost - dbjobs When you are done, revert the changes you made to database_jobs/k8s/values.yaml . Operator ï This is a very simple deployment of the application that manages the rest of the Boost applications. Usually the only maintenance needed here will be to change to a new version of the Docker image in operator/k8s/values.yaml . Stack ï This Helm chart creates the Boost Stack definition in Kubernetes, which is in turn read by the previously mentioned operator which will deploy all the Boost applications from the Stack definition. To have a quick glance at the Kubernetes object created by this chart: kubectl get stack boostai - stack - o json | yq e - P Or if you donât have the yq tool available just do: kubectl get stack boostai - stack - o yaml | less For information about configuration, please consult Boost. To see what application instances have been created from the Stack definition by the operator: kubectl get pods - l network_aws_access = true Previous Next © Copyright 2024, TNT. Built with Sphinx using a theme provided by Read the Docs .