Ceph — SBAB Docs  documentation SBAB Docs Ansible Controller Ansible Roles Ansible Vault Argo Workflows Authentication & Authorization Bitbucket Boost Chatbot Booli Ceph Fix crashing OSD pods Ceph multi-site Overview Deployment Design Cluster sync addresses Operations Deploy Once the clusters are up and running and beyond Troubleshooting and status checking Dex Fortigate troubleshooting Generate certificate Go GitHub Copilot GitLab @Sbab User Guide GitLab Maintenance Grafana Istio Java Jenkins Jenkinsfile Jmeter Kafka Maintenance Kafka @Sbab User Guide Kafka Connect Kubectl Access Kubernetes Lab environment Local Open Web Metrics infrastructure MongoDB Netbox NVIDIA Neo4J Sonatype Nexus repository Oracle OWASP Database OWASP @Sbab User Guide Pact Principles of Security Prometheus ReactJS Redis Renovate S3 Security Guidelines for Developers Sentry Maintenance Sentry User Guide Configuring Variables for Services Deployed to Kubernetes Software Architecture SonarQube Maintenance SonarQube User Guide Structurizr System Landscape Vagrant Zipkin Windows Pipelines SBAB Docs » Ceph View page source Ceph ï Fix crashing OSD pods ï Things to consider: if you have several OSDs crashing, you need to make sure you have enough space to remove the broken OSDs. You may have to remove 1 OSD at a time, wait for rebalancing and then recreate those OSD before you remove more broken OSDs. Find out which worker node the problematic OSD/s is on. WRITE IT DOWN before you proceed. kubectl -n rook-ceph get pods -l app=rook-ceph-osd -o wide Stop the operator from trying to consume broken disks. kubectl -n rook-ceph scale deployment rook-ceph-operator --replicas=0 Also stop the deployments of the broken OSDs. kubectl -n rook-ceph scale deployment rook-ceph-osd-<OSD_ID> --replicas=0 Get the ID of the OSD that is crashing, make sure the status is DOWN. kubectl -n rook-ceph exec -it deploy/rook-ceph-operator -- ceph osd df Next step is to purge the OSD from the cluster. There is a Kubernetes job to purge OSDs. If you have several OSDs, you need to delete the old job and recreate it since Job specs are immutable. Change the <OSD_ID> parameter. _ NOTE : The job rook image version must match your rook version running on the cluster. You can get the correct Job version on Github . By choosing the correct TAG apiVersion : batch / v1 kind : Job metadata : name : rook - ceph - purge - osd namespace : rook - ceph labels : app : rook - ceph - purge - osd spec : template : spec : serviceAccountName : rook - ceph - system containers : - name : osd - removal image : rook / ceph : v1 .5.1 # TODO: Insert the OSD ID in the last parameter that is to be removed # The OSD IDs are a comma-separated list. For example: "0" or "0,2". args : [ "ceph" , "osd" , "remove" , "--osd-ids" , "<OSD_ID" ] env : - name : POD_NAMESPACE valueFrom : fieldRef : fieldPath : metadata . namespace - name : ROOK_MON_ENDPOINTS valueFrom : configMapKeyRef : key : data name : rook - ceph - mon - endpoints - name : ROOK_CEPH_USERNAME valueFrom : secretKeyRef : key : ceph - username name : rook - ceph - mon - name : ROOK_CEPH_SECRET valueFrom : secretKeyRef : key : ceph - secret name : rook - ceph - mon - name : ROOK_CONFIG_DIR value : / var / lib / rook - name : ROOK_CEPH_CONFIG_OVERRIDE value : / etc / rook / config / override . conf - name : ROOK_FSID valueFrom : secretKeyRef : key : fsid name : rook - ceph - mon - name : ROOK_LOG_LEVEL value : DEBUG volumeMounts : - mountPath : / etc / ceph name : ceph - conf - emptydir volumes : - emptyDir : {} name : ceph - conf - emptydir restartPolicy : Never Now you need to wait for rebalancing.. Run a watch on the Ceph -s command and await rebalancing. Check the pgs x/x objects degraded (xx.xxx%) and makes sure the procentage is decreasing. If you have many problematic OSDs this may take some timeâ¦ If you donât get down to 0% try and start a broken OSD deployment. If that doesnât help, you may have dataloss. watch -n1 kubectl -n rook-ceph exec -it deploy/rook-ceph-operator -- ceph -s While you wait for Ceph to rebalance you can zap and recreate the broken disk on the worker node for the broken OSD. openstack --os-cloud=<OS_CLOUD> server remove volume <server> <volume> openstack --os-cloud=<OS_CLOUD> volume delete <volume> openstack --os-cloud=<OS_CLOUD> volume create --size <size> <volume> openstack --os-cloud=<OS_CLOUD> server add volume <server> <volume> Then you can start the operator again when the Cluster rebalancing is done! NOTE: If an OSD is not consumed. You can try and check the auth list inside ceph to make sure the key for that OSD was properly removed. ceph auth list Ceph multi-site ï Overview ï This document describes the multi-site setup for S3 object storage with Ceph. Multi-site sync is currently at the writing only available for object storage. A multi-site cluster contains one primary cluster, then one, or multiple, secondary clusters, preferably located at different sites.
You can run multiple cluster on the same site, however this is not tracked by the k8s_cluster_storage_rook role . There is a lot of configuration to be done for your cluster(s), so please read through the role readme , and also understand how to configure the rook-ceph operator . Deployment ï To deploy a multi-site object storage you will have to: Deploy a Kubernetes cluster . Deploy the rook-ceph operator, and configuration through the role k8s_cluster_storage_rook using the playbooks k8s/cluster_services/k8s_cluster_storage_rook.yml for the primary cluster, and k8s/cluster_services/k8s_cluster_storage_rook_secondary_site.yml for the secondary cluster(s). Design ï Rook-ceph uses the built in support from Ceph for the object storage multi-site support . The multi-site support, where multiple clusters are able to sync with each other are called a âRealmâ. There can only be one primary cluster, which manages everything, and the rest of the clusters will be secondary. A cluster can have multiple realms, both local and replicated. Each realm can have multiple Buckets where you read and write your data, and access is based on the Buckets. The design is that we deploy one Ceph cluster per site in a specific environment, where a realm will be deployed on all the clusters handling the Object storage.
Then the object storage will be available, and replicated, to the multiple sites. This means that you can write, and read, to each of the clusters at the same time, although it is not recommended that you write to multiple clusters, but only the primary cluster. In case the primary cluster goes down, you will have to manually failover the cluster, however as Ceph by default allows writes to a secondary cluster, the service will still continue to function. Cluster sync addresses ï As we are currently running our K8S clusters with internal IP addresses, Rook-ceph is unable to handle this, and canât expose the service(s) to other clusters in the Realm. To do this we need to use the external service IP address that we have for the K8S cluster, and point a service address (URL) instead, it is therefore important to set the ingress route for S3. It is good to know that this is done outside of the rook-ceph operator, directly in Ceph. Each cluster that you use are required to have their own unique service address for the S3 object storage, for example ceph-s3-ms-<SITE>.<ENV>.sbab.se . This would then access the proper S3 service based on the credentials you provide. Operations ï Deploy ï You deploy through the following playbooks: k8s/cluster_services/k8s_cluster_storage_rook.yml k8s/cluster_services/k8s_cluster_storage_rook_secondary_site.yml Primary cluster ï You must always deploy the primary cluster first. Run the playbook k8s/cluster_services/k8s_cluster_storage_rook.yml with the inventory you wish to use, and use the variable primary_master to decide where to run the plays: ansible - playbook - i inventories /< INVENTORY > playbooks / k8s / cluster_services / k8s_cluster_storage_rook . yml - e primary_master = k8s - m2 -< SITE > This will setup your primary master which will be the master for the Ceph realm. Once finished, verify that ceph is up and running OK: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- ceph status cluster : id : 0 ac31f4a - 2 b49 - 47 f6 - ab31 - 3 c3358280911 health : HEALTH_OK Health should be OK. Then we will verify that the sync for your object zone groups are up and running: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- radosgw - admin sync status realm 5 bdc9e7f - b126 - 44 b2 - 9 ac8 - f06bc9eb77e1 ( realm - lab ) zonegroup 70 f80337 - 4 a18 - 46e0 - 8221 - ef5120608950 ( zonegroup - lab ) zone 33 a50ca2 - 6 fa5 - 4945 - adf1 - f0e6ec87bdf4 ( zone - lab - uv ) metadata sync no sync ( zone is master ) The URL endpoint to your primary cluster must be the same for all the secondary clusters you setup, that will be sharing the same realm(s). Secondary cluster ï Once you have your primary (master) cluster up and running, you will setup your secondary cluster(s). They will all point to the same primary cluster. Run the playbook k8s/cluster_services/k8s_cluster_storage_rook_secondary_site.yml with the inventory you wish to use, and use the variables primary_master and primary_cluster_master to decide where to run the plays: ansible - playbook - i inventories /< INVENTORY > playbooks / k8s / cluster_services / k8s_cluster_storage_rook_secondary_site . yml - e \ 'primary_cluster_master=k8s-m2-<PRIMARYCLUSTERSITE> \ primary_master=k8s-m2-<SECONDARYCLUSTERSITE>' Repeat this for all your secondary clusters. Once the site is up and running you can now verify that Ceph is up and running. On both the primary and secondary clusters you can verify the zone group, you should now see both the primary and secondary cluster in the output, with the correct endpoint URLs for all the zones that you have just created: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- radosgw - admin zonegroup get { "id" : "70f80337-4a18-46e0-8221-ef5120608950" , "name" : "zonegroup-lab" , "api_name" : "zonegroup-lab" , "is_master" : "true" , "endpoints" : [ "http://172.16.16.37:80" ], "hostnames" : [], "hostnames_s3website" : [], "master_zone" : "33a50ca2-6fa5-4945-adf1-f0e6ec87bdf4" , "zones" : [ { "id" : "33a50ca2-6fa5-4945-adf1-f0e6ec87bdf4" , "name" : "zone-lab-uv" , "endpoints" : [ "https://ceph-s3-mr-uv.lab.sbab.se" ], "log_meta" : "false" , "log_data" : "true" , "bucket_index_max_shards" : 11 , "read_only" : "false" , "tier_type" : "" , "sync_from_all" : "true" , "sync_from" : [], "redirect_zone" : "" }, { "id" : "38b57c5e-37e6-46fd-98d6-5af1b26c5136" , "name" : "zone-lab-ki" , "endpoints" : [ "https://ceph-s3-mr-ki.lab.sbab.se" ], "log_meta" : "false" , "log_data" : "true" , "bucket_index_max_shards" : 11 , "read_only" : "false" , "tier_type" : "" , "sync_from_all" : "true" , "sync_from" : [], "redirect_zone" : "" } ], "placement_targets" : [ { "name" : "default-placement" , "tags" : [], "storage_classes" : [ "STANDARD" ] } ], "default_placement" : "default-placement" , "realm_id" : "5bdc9e7f-b126-44b2-9ac8-f06bc9eb77e1" , "sync_policy" : { "groups" : [] } } You will now have a syncing Object storage. Once the clusters are up and running and beyond ï Once you have deployed your clusters, you will have to deploy a ObjectBucketClaim to create the actual bucket where you will upload your data. For example: - name : Create ObjectBucketClaim community.kubernetes.k8s : apply : yes resource_definition : apiVersion : objectbucket.io/v1alpha1 kind : ObjectBucketClaim metadata : name : ceph-bucket namespace : rook-ceph spec : bucketName : ceph-bucket storageClassName : rook-ceph-retain-bucket You can now verify that your clusters are syncing as they should by uploading to the primary cluster, and it should be available if you also connect to the secondary cluster. You can see the sync status by using the following command, on all your clusters: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- radosgw - admin sync status realm 5 bdc9e7f - b126 - 44 b2 - 9 ac8 - f06bc9eb77e1 ( realm - lab ) zonegroup 70 f80337 - 4 a18 - 46e0 - 8221 - ef5120608950 ( zonegroup - lab ) zone 33 a50ca2 - 6 fa5 - 4945 - adf1 - f0e6ec87bdf4 ( zone - lab - uv ) metadata sync no sync ( zone is master ) data sync source : 38 b57c5e - 37e6 - 46 fd - 98 d6 - 5 af1b26c5136 ( zone - lab - ki ) syncing full sync : 0 / 128 shards incremental sync : 128 / 128 shards data is caught up with source Once you have verified that it works, you are good to go. Troubleshooting and status checking ï Any timeouts or error messages while running these commands need to be investigated, as that is an indication that something is not running as it should. To check the ceph status: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- ceph status Verify that the ceph cluster has all your OSDâs available, and that the health is OK. To check sync status: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- radosgw - admin sync status To check the zone group status: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- radosgw - admin zonegroup get You should only see the specified URL endpoints in the zones, no IP addresses, for example: { "id" : "33a50ca2-6fa5-4945-adf1-f0e6ec87bdf4" , "name" : "zone-lab-uv" , "endpoints" : [ "https://ceph-s3-mr-uv.lab.sbab.se" ], "log_meta" : "false" , "log_data" : "true" , "bucket_index_max_shards" : 11 , "read_only" : "false" , "tier_type" : "" , "sync_from_all" : "true" , "sync_from" : [], "redirect_zone" : "" }, To check the zone status: kubectl - n rook - ceph exec - it deployment . apps / rook - ceph - tools -- radosgw - admin zone get Previous Next © Copyright 2024, TNT. Built with Sphinx using a theme provided by Read the Docs .