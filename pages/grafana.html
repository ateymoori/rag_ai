Grafana — SBAB Docs  documentation SBAB Docs Ansible Controller Ansible Roles Ansible Vault Argo Workflows Authentication & Authorization Bitbucket Boost Chatbot Booli Ceph Dex Fortigate troubleshooting Generate certificate Go GitHub Copilot GitLab @Sbab User Guide GitLab Maintenance Grafana URLâs Make a Spring Boot service available in Grafana Dashboards Alerts Default channels Custom channels Toggle alerts Useful queries Online application instances See running versions Restarts (crashes) Memory usage CPU usage HTTP requests per second HTTP requests time Deploy Grafana Credentials Istio Java Jenkins Jenkinsfile Jmeter Kafka Maintenance Kafka @Sbab User Guide Kafka Connect Kubectl Access Kubernetes Lab environment Local Open Web Metrics infrastructure MongoDB Netbox NVIDIA Neo4J Sonatype Nexus repository Oracle OWASP Database OWASP @Sbab User Guide Pact Principles of Security Prometheus ReactJS Redis Renovate S3 Security Guidelines for Developers Sentry Maintenance Sentry User Guide Configuring Variables for Services Deployed to Kubernetes Software Architecture SonarQube Maintenance SonarQube User Guide Structurizr System Landscape Vagrant Zipkin Windows Pipelines SBAB Docs » Grafana View page source Grafana ï Grafana allows you to query, visualize, alert on and understand your metrics. URLâs ï Sys: https://grafana.sys.sbab.se Acc: https://grafana.acc.sbab.se Stage: https://grafana.stage.sbab.se Production: https://grafana.prod.sbab.se Make a Spring Boot service available in Grafana ï To make your service show up in Grafana you need to expose the service to Prometheus which provides the data to Grafana. Add the actuator dependency to your pom.xml <dependency> <groupId> org.springframework.boot </groupId> <artifactId> spring-boot-starter-actuator </artifactId> </dependency> Actuator exposes metrics in a format that can be scraped by a Prometheus server. It requires a dependency on micrometer-registry-prometheus to work. Add the micrometer dependency: <dependency> <groupId> io.micrometer </groupId> <artifactId> micrometer-registry-prometheus </artifactId> </dependency> Add the following settings to your application.yml file: management:
  endpoints:
    web:
      base-path: /admin
      exposure:
        include: prometheus,info,health
      path-mapping:
        health: healthcheck
        prometheus: prometheusMetrics Add service_scrape_path to your Jenkinsfile. Example: https://docs.sbab.se/jenkinsfile.html#prometheus-metrics to tell Prometheus to âgo look for dataâ in you service. Exchange âpartner-auth-serviceâ with the name of your service. Commit and push your changes to your dev and master branch and it should then be possible to create Dashboards for your service in all environments. Dashboards ï Go to Grafana for the sys environment and create/edit your dashboards Make sure that title and uid are unique across all dashboards (not copied from another dashboard) Press the share dashboard button (top right corner) and export to json file Ensure the value of the id key is null in the JSON file - ie. jq '.id=null' file.json > newfile.json Add or overwrite the JSON file in grafana/dashboards (name of your choice) Create a Pull Request from your feature branch towards the dev branch and Deploy Grafana Tip Search Splunk using source="grafana.common" lvl=eror to find configuration errors Alerts ï It is possible to define alerts for every query/graph. See the example for security-service , which
alerts both in the default channels and in the custom alerts-tnt channels. Default channels ï Sys Acc Stage Production #alerts-sys #alerts-acc #alerts-stage #alerts Custom channels ï A team can setup dedicated alert channels if the team does not want to see alerts from other teams. In this example, the
TNT team uses #alerts-tnt-test for alerts in all development environments and #alerts-tnt-prod for production. Create two new channels, #alerts-<team name>-test and #alerts-<team name>-prod Contact #team-tnt and ask to get webhooks for your 2 new channels: Sys Webhook Acc Webhook Stage Webhook Prod Webhook Update slack_alert_channels with alerts-<team name>: <webhook url> for each environment: inventories/ossys/group_vars/all/grafana.yml inventories/osacc/group_vars/all/grafana.yml inventories/osstage/group_vars/all/grafana.yml inventories/osprod/group_vars/all/grafana.yml Deploy Grafana to all environments Toggle alerts ï To disable all alerts in e.g. https://grafana.sys.sbab.se/alerting/list : ansible - playbook -- inventory inventories / ossys playbooks / toggle - grafana - alerts . yml \ -- extra - vars disable_alerts = true To enable all alerts: ansible - playbook -- inventory inventories / ossys playbooks / toggle - grafana - alerts . yml \ -- extra - vars enable_alerts = true Useful queries ï Here are a few useful queries to see information about the state of your application instances. Try them out in https://grafana.sys.sbab.se or https://thanos-query.sys.sbab.se Demo dashboard at https://grafana.sys.sbab.se/d/sCLlDqsGz/generic-queries-demo?orgId=1 Note None of these queries requires the application itself to have Prometheus metrics configured. Online application instances ï kube_pod_container_status_ready { container = "partner-auth-service" } Wrap in sum() to get a simple count: sum ( kube_pod_container_status_ready { container = "partner-auth-service" }) See running versions ï To see what version of your code is running on the application instances: kube_pod_container_info { container = "partner-auth-service" } The image label will contain a string similar to: nexus . common . sbab . se : 18443 / se . sbab / partner - auth - service : 20201022160255 - 0 cb9aee So the final part of the URL is: service:buildtime-githash Restarts (crashes) ï Application instances can restart for many reasons, but if you are seeing more than 5 restarts something is almost certainly wrong. kube_pod_container_status_restarts_total { container = "partner-auth-service" } Memory usage ï Current memory usage: sum ( container_memory_working_set_bytes { container = "partner-auth-service" }) by ( pod ) To put this in perspective it is useful to have a 2nd query for the panel to show the memory limit where the instances will be killed for consuming too much memory: avg ( kube_pod_container_resource_limits_memory_bytes { container = "partner-auth-service" }) Note In Grafana set the Unit for the left Y Axis to bytes(IEC) CPU usage ï Current CPU usage: node_namespace_pod_container : container_cpu_usage_seconds_total : sum_rate { container = "partner-auth-service" } To put this in perspective it is useful to have a 2nd query for the panel to show the CPU limit where the instances will be killed for consuming too much CPU: avg ( kube_pod_container_resource_limits_cpu_cores { container = "partner-auth-service" }) HTTP requests per second ï This query will NOT show requests directly between applications, ie calls to http://service:8080/ Group by HTTP status code and HTTP method: sum ( rate ( traefik_service_requests_total { service =~ "^.*partner-auth-service.*kubernetescrd" }[ 10 m ])) by ( code , method ) Just get the total for all types of requests: sum ( rate ( traefik_service_requests_total { service =~ "^.*partner-auth-service.*kubernetescrd" }[ 10 m ])) HTTP requests time ï This query will NOT show requests directly between applications, ie calls to http://service:8080/ The query will show the 90th percentile of request durations over the last 10m by HTTP method and status code: histogram_quantile ( 0.90 , sum by ( method , code , le ) ( rate ( traefik_service_request_duration_seconds_bucket { service =~ "^.*partner-auth-service.*kubernetescrd" }[ 10 m ]))) Only group by HTTP method: histogram_quantile ( 0.90 , sum by ( method , le ) ( rate ( traefik_service_request_duration_seconds_bucket { service =~ "^.*partner-auth-service.*kubernetescrd" }[ 10 m ]))) Only group by HTTP status code: histogram_quantile ( 0.90 , sum by ( code , le ) ( rate ( traefik_service_request_duration_seconds_bucket { service =~ "^.*partner-auth-service.*kubernetescrd" }[ 10 m ]))) Note In Grafana set the Unit for the left Y Axis to seconds Deploy Grafana ï Navigate to the grafana Jenkins job Select the desired branch Click the Build Now button Sys will be deployed when the dev branch is built Acc, Stage and Production will be deployed when the master branch is built Credentials ï Username Password admin inventories/os<env>/group_vars/all/grafana-vault.yml Previous Next © Copyright 2024, TNT. Built with Sphinx using a theme provided by Read the Docs .